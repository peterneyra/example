{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4579b247397d5f",
   "metadata": {},
   "source": [
    "## Yellow Taxi Tripdata\n",
    "### Bereinigung und Vorbereitung\n",
    "\n",
    "#### Data Cleansing (Datenbereinigung)\n",
    "Data Cleansing konzentriert sich darauf, schlechte Daten zu finden und zu beheben. Es geht um die Qualität der Daten. Stell dir vor, du korrigierst einen Text auf Rechtschreibfehler, fehlende Wörter oder doppelte Sätze.\n",
    "\n",
    "Typische Aufgaben sind:\n",
    "\n",
    "- Fehlende Werte auffüllen oder entfernen.\n",
    "\n",
    "- Doppelte Datensätze löschen.\n",
    "\n",
    "- Inkonsistente Einträge korrigieren (z. B. \"USA\" und \"Vereinigte Staaten\" zu standardisieren).\n",
    "\n",
    "- Ausreißer und unsinnige Werte entfernen.\n",
    "\n",
    "#### Data Wrangling (Datenaufbereitung)\n",
    "Data Wrangling ist der übergeordnete, umfassende Prozess, um Rohdaten in eine nutzbare Form für die Analyse zu bringen. Es ist wie das gesamte Schreiben eines Berichts, nicht nur das Korrigieren. Es beinhaltet das Cleansing, geht aber noch weit darüber hinaus.\n",
    "\n",
    "Typische Aufgaben sind:\n",
    "\n",
    "- Das Cleansing der Daten.\n",
    "\n",
    "- Das Verknüpfen mehrerer Datensätze (wie wir mit dem lookup_df machen werden).\n",
    "\n",
    "- Das Umstrukturieren der Daten (z. B. Spalten in Zeilen umwandeln).\n",
    "\n",
    "- Das Anreichern der Daten (z. B. neue Spalten für \"Tag der Woche\" erstellen).\n",
    "\n",
    "**Zusammenfassend**: Das Ziel von Cleansing ist es, die Daten sauber und korrekt zu machen. Das Ziel von Wrangling ist es, die sauberen Daten bereit für die Analyse zu machen.\n",
    "\n",
    "Zuerst widmen wir uns der Bereinigung des großen DataFrames. Wir korrigieren die Datentypen der Spalten, insbesondere der Datums- und Zeitangaben, kümmern uns um fehlende Werte und filtern offensichtliche Fehler wie Fahrten mit 0 Dollar Preis oder 0 Minuten Dauer heraus. Ziel ist ein sauberer, zuverlässiger Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c227ced0a3bb31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import pyarrow\n",
    "from fastparquet import ParquetFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af3b0eb352a36b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen des Parquet-Files\n",
    "pf = ParquetFile('NYTaxi-TripData/yellow_tripdata.parquet')\n",
    "df = pf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5be67d431a99bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-11-01 00:30:41</td>\n",
       "      <td>2019-11-01 00:32:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-11-01 00:34:01</td>\n",
       "      <td>2019-11-01 00:34:09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-11-01 00:41:59</td>\n",
       "      <td>2019-11-01 00:42:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-11-01 00:02:39</td>\n",
       "      <td>2019-11-01 00:02:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-11-01 00:18:30</td>\n",
       "      <td>2019-11-01 00:18:39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0       1.0  2019-11-01 00:30:41   2019-11-01 00:32:25              1.0   \n",
       "1       1.0  2019-11-01 00:34:01   2019-11-01 00:34:09              1.0   \n",
       "2       2.0  2019-11-01 00:41:59   2019-11-01 00:42:23              1.0   \n",
       "3       2.0  2019-11-01 00:02:39   2019-11-01 00:02:51              1.0   \n",
       "4       2.0  2019-11-01 00:18:30   2019-11-01 00:18:39              2.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            0.0         1.0                  N           145           145   \n",
       "1            0.0         1.0                  N           145           145   \n",
       "2            0.0         1.0                  N           193           193   \n",
       "3            0.0         1.0                  N           193           193   \n",
       "4            0.0         1.0                  N           226           226   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0           2.0          3.0    0.5      0.5        0.00           0.0   \n",
       "1           2.0          2.5    0.5      0.5        0.00           0.0   \n",
       "2           1.0          2.5    0.5      0.5        0.95           0.0   \n",
       "3           1.0          2.5    0.5      0.5        0.95           0.0   \n",
       "4           2.0          2.5    0.0      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3          4.30                   0.0  \n",
       "1                    0.3          3.80                   0.0  \n",
       "2                    0.3          4.75                   0.0  \n",
       "3                    0.3          4.75                   0.0  \n",
       "4                    0.3          3.30                   0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f559e39ea2d73192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101246797 entries, 0 to 101246796\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   VendorID               float64\n",
      " 1   tpep_pickup_datetime   object \n",
      " 2   tpep_dropoff_datetime  object \n",
      " 3   passenger_count        float64\n",
      " 4   trip_distance          float64\n",
      " 5   RatecodeID             float64\n",
      " 6   store_and_fwd_flag     object \n",
      " 7   PULocationID           int64  \n",
      " 8   DOLocationID           int64  \n",
      " 9   payment_type           float64\n",
      " 10  fare_amount            float64\n",
      " 11  extra                  float64\n",
      " 12  mta_tax                float64\n",
      " 13  tip_amount             float64\n",
      " 14  tolls_amount           float64\n",
      " 15  improvement_surcharge  float64\n",
      " 16  total_amount           float64\n",
      " 17  congestion_surcharge   float64\n",
      "dtypes: float64(13), int64(2), object(3)\n",
      "memory usage: 13.6+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82738879e47ee949",
   "metadata": {},
   "source": [
    "### Legende\n",
    "#### Bevor wir so richtig loslegen hier noch eine Übersicht über die Bedeutung der Spalten:\n",
    "##### Die Einträge in einigen Spalten referenzieren Werte die auch nachfolgend angegeben sind.\n",
    "- `VendorID`: Eine ID des Taxi-Anbieters (z. B. 1 für Creative Mobile Technologies, 2 für Curb Mobility).\n",
    "    - 1: Creative Mobile Technologies, LLC\n",
    "    - 2: VeriFone Inc.\n",
    "\n",
    "- `tpep_pickup_datetime`: Das Datum und die Uhrzeit, wann die Taxifahrt begonnen hat.\n",
    "\n",
    "- `tpep_dropoff_datetime`: Das Datum und die Uhrzeit, wann die Fahrt beendet wurde.\n",
    "\n",
    "- `passenger_count`: Die Anzahl der Passagiere auf der Fahrt.\n",
    "\n",
    "- `trip_distance`: Die zurückgelegte Entfernung in Meilen.\n",
    "\n",
    "- `PULocationID`: Die ID der Zone, in der die Fahrt begonnen hat. (Zone-Lookup-Frame)\n",
    "\n",
    "- `DOLocationID`: Die ID der Zone, in der die Fahrt geendet hat.  (Zone-Lookup-Frame)\n",
    "\n",
    "- `RatecodeID`: Ein Code für den Tarif der Fahrt (z. B. 1 = Standard, 2 = Fahrt zum JFK-Flughafen).\n",
    "    - 1: Standard rate\n",
    "    - 2: JFK\n",
    "    - 3: Newark\n",
    "    - 4: Nassau or Westchester\n",
    "    - 5: Negotiated fare\n",
    "    - 6: Group ride\n",
    "- `payment_type`: Der Zahlungs-Typ (z. B. 1 = Kreditkarte, 2 = Barzahlung).\n",
    "    - 1: Credit card\n",
    "    - 2: Cash\n",
    "    - 3: No charge\n",
    "    - 4: Dispute\n",
    "    - 5: Unknown\n",
    "    - 6: Voided trip\n",
    "\n",
    "- `fare_amount`: Der reine Fahrpreis (ohne Extras).\n",
    "\n",
    "- `congestion_surcharge`: Eine eventuell erhobene Staugebühr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94acd070b49346",
   "metadata": {},
   "source": [
    "#### store_and_fwd_flag\n",
    "Hier noch eine Erklärung zu der Spalte store_and_fwd_flag:\n",
    "Das `store_and_fwd_flag` sagt aus, ob die Daten einer Taxifahrt sofort an den Server des Anbieters gesendet werden konnten oder nicht.\n",
    "\n",
    "Wenn das Signal im Taxi schlecht war, wurden die Daten lokal auf dem Taxameter gespeichert (store) und erst später, als die Verbindung wieder da war, weitergeleitet (forward).\n",
    "- 'Y': Die Daten wurden erst später weitergeleitet.\n",
    "- 'N': Die Daten wurden sofort gesendet.\n",
    "\n",
    "Für eine erste, einfache Analyse ist der store_and_fwd_flag vielleicht nicht das wichtigste Feature.\n",
    "\n",
    "Aber es kann wichtig sein, um die Datenqualität zu beurteilen. Wenn viele Fahrten dieses Flag haben, könnte das auf ein schlechtes GPS-Signal hindeuten, was wiederum die Genauigkeit der Fahrzeiten und der Entfernungen beeinflussen kann. Das wäre dann ein wichtiger Punkt, den man bei der Interpretation der Ergebnisse berücksichtigen müsste.\n",
    "\n",
    "Auch könnte es sein, dass es für Machine-Learning-Modelle wichtig ist. Vielleicht gibt es einen Zusammenhang zwischen dem Flag und der Höhe des Trinkgeldes oder der Fahrtdauer. Aber das sind eher fortgeschrittene Themen.\n",
    "\n",
    "Kurz gesagt: Es ist ein kleiner, aber feiner Hinweis auf die Umstände, unter denen die Daten gesammelt wurden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c303f067bbc4c1",
   "metadata": {},
   "source": [
    "#### Datentypen korrigieren\n",
    "Der erste Schritt ist, die Datentypen der Datums- und Zeitspalten korrekt einzustellen. Wie wir besprochen haben, müssen die Spalten tpep_pickup_datetime und tpep_dropoff_datetime in das datetime-Format umgewandelt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61be1b5a7bc3cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101246797 entries, 0 to 101246796\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               float64       \n",
      " 1   tpep_pickup_datetime   datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  datetime64[ns]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           float64       \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      "dtypes: datetime64[ns](2), float64(13), int64(2), object(1)\n",
      "memory usage: 13.6+ GB\n"
     ]
    }
   ],
   "source": [
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f458b51311737eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                 527484\n",
       "passenger_count          527484\n",
       "RatecodeID               527484\n",
       "store_and_fwd_flag       527484\n",
       "payment_type             527484\n",
       "congestion_surcharge    4855981\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.isnull().sum <- ergibt eine unübersichliche Ausgabe\n",
    "\n",
    "# wir sind nur an Spalten interessiert, die mindestens 1 fehlenden Wert haben.\n",
    "df.isnull().sum()[df.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eaa2b04fcaab92",
   "metadata": {},
   "source": [
    "Für die `congestion_surcharge`Wert gehen wir davon aus, dass für die Fahrt keine Staugebühr erhoben wurde.\n",
    "Wir ersetzen die fehlenden Werte (NaN) durch eine 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "913252037dde1ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID              527484\n",
       "passenger_count       527484\n",
       "RatecodeID            527484\n",
       "store_and_fwd_flag    527484\n",
       "payment_type          527484\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ersetze alle fehlenden Werte in der congestion_surcharge-Spalte durch 0\n",
    "#df['congestion_surcharge'].fillna(0, inplace=True) <-- erzeugt eine Warnung\n",
    "\n",
    "# So geht es ohne Warnmeldung\n",
    "df['congestion_surcharge'] = df['congestion_surcharge'].fillna(0)\n",
    "\n",
    "# Nochmal die Ausgabe zur Kontrolle\n",
    "df.isnull().sum()[df.isnull().sum() > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b276f73f87be724d",
   "metadata": {},
   "source": [
    "#### Interpretation der Fehlwerte\n",
    "Die Tatsache, dass alle fünf Spalten exakt die gleiche Anzahl an fehlenden Werten haben, ist ein sehr starkes Signal. Es ist höchst unwahrscheinlich, dass das Zufall ist.\n",
    "\n",
    "##### Interpretation:\n",
    "Diese 527.484 fehlenden Werte betreffen wahrscheinlich die gleichen Fahrten. Es scheint, als wären für diese Trips aus irgendeinem Grund die Daten für alle diese Spalten auf einmal nicht erfasst worden.\n",
    "\n",
    "##### Nächster Schritt:\n",
    "Da uns für diese Fahrten so viele wichtige Informationen fehlen, sind die Zeilen für unsere Analyse wahrscheinlich nicht nutzbar. Die beste Methode, um damit umzugehen, ist, diese Zeilen einfach aus dem Datensatz zu entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23cad95bcfc331f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101246797, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (vorher)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e87023bef1c08b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['VendorID', 'passenger_count', 'RatecodeID', 'store_and_fwd_flag', 'payment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3e9db933d47e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100719313, 18)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (nachher) - Die Differenz sollte wieder 527.484 ergeben...\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e27cdd651d5e6",
   "metadata": {},
   "source": [
    "- Die Methode `dropna()` entfernt Zeilen mit fehlenden Werten (NaN, None, etc.)\n",
    "- Der Parameter `subset` gibt an, dass nur die genannten Spalten auf fehlende Werte überprüft werden sollen\n",
    "- Es werden nur Zeilen entfernt, die in mindestens einer der folgenden Spalten fehlende Werte haben:\n",
    "    - 'VendorID'\n",
    "    - 'passenger_count'\n",
    "    - 'RatecodeID'\n",
    "    - 'store_and_fwd_flag'\n",
    "    - 'payment_type'\n",
    "\n",
    "- Das Ergebnis wird dem ursprünglichen DataFrame `df` zugewiesen, was bedeutet, dass der originale DataFrame überschrieben wird\n",
    "\n",
    "Diese Operation ist typisch für die Datenbereinigung, wobei unvollständige Datensätze entfernt werden, bevor weitere Analysen durchgeführt werden. Alterntiv können wir natürlich auch fehlende Daten einfach ersetzten - dazu werden wir später noch mehr erfahren.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5add794d753b4c",
   "metadata": {},
   "source": [
    "#### Filtern unnötiger Datensätze\n",
    "Wir filtern den Datensatz so, dass nur noch Fahrten übrig bleiben, bei denen sowohl die Entfernung als auch der Fahrpreis größer als 0 sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da26e7a5dde8baac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99574711, 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtert den DataFrame, um nur Fahrten mit trip_distance und fare_amount größer 0 zu behalten\n",
    "df = df[(df['trip_distance'] > 0) & (df['fare_amount'] > 0)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ccd96d2a0ac89",
   "metadata": {},
   "source": [
    "### Speichern & Feierabend\n",
    "Natürlich wollen wir unseren schönen, sauberen und bereinigten Datensatz für zukünftige Missionen speichern!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "805565d78b2ef7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des aktuellen Dataframes\n",
    "df.to_parquet('NYTaxi-TripData/new_york_taxi_cleaned.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edeb2ded5cb522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86a32a72dd0b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5a8235a1a5934b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
